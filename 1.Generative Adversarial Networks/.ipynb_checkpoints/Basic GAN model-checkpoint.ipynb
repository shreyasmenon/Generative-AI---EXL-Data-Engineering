{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04ea1947",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import glob\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "from tensorflow.keras import layers\n",
    "import time\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8b099a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (_, _) = tf.keras.datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2184ca2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "913ccb5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images.reshape(train_images.shape[0], 28, 28, 1).astype('float32')\n",
    "#train_images = (train_images - 127.5) / 127.5 # Normalize the images to [-1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d4e1978",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f93702a16d0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(train_images[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "acfb1bf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-21 14:19:54.163338: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-21 14:19:54.163988: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 8. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "BUFFER_SIZE = 60000\n",
    "BATCH_SIZE = 256\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(train_images).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3415138d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for Generator of GAN\n",
    "def make_generator_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Dense(7*7*256, use_bias=False, input_shape=(100,)))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "    \n",
    "    model.add(layers.Reshape((7, 7, 256)))\n",
    "    assert model.output_shape == (None, 7, 7, 256) # Note: None is the batch size\n",
    "    \n",
    "    model.add(layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False))\n",
    "    assert model.output_shape == (None, 7, 7, 128)\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
    "    assert model.output_shape == (None, 14, 14, 64)\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))\n",
    "    assert model.output_shape == (None, 28, 28, 1)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc1abd4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f9372b58050>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# View a sample image generated by the the generator\n",
    "generator = make_generator_model()\n",
    "noise = tf.random.normal([1, 100])\n",
    "\n",
    "#here we supply noise as an input\n",
    "#Note - model is not trained on anything\n",
    "generated_image = generator(noise, training=False)\n",
    "plt.imshow(generated_image[0, :, :, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7a13f0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for Discriminator of GAN\n",
    "def make_discriminator_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same', input_shape=[28, 28, 1]))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(1)) #This will predict a binary outcome\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "904e0b0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[-0.00146395]], shape=(1, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#positive value for the real image and a negative value for the fake image.\n",
    "discriminator = make_discriminator_model()\n",
    "decision = discriminator(generated_image)\n",
    "print(decision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e528dc2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross entropy loss\n",
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "90818733",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The discriminator loss function quantifies how well the discriminator is able to distinguish real images from fakes. \n",
    "#It compares the discriminator’s predictions on real images to an array of 1s, and the discriminator’s predictions on fake (generated) images to an array of 0s.\n",
    "def discriminator_loss(real_output, fake_output):\n",
    "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "    total_loss = real_loss + fake_loss\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "52a81b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_loss(fake_output):\n",
    "    return cross_entropy(tf.ones_like(fake_output), fake_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b1582fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optimizer\n",
    "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c621e276",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 100\n",
    "noise_dim = 100\n",
    "num_examples_to_generate = 16\n",
    "# We will reuse this seed overtime (so it's easier) to visualize progress in the animated GIF)\n",
    "seed = tf.random.normal([num_examples_to_generate, noise_dim])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "79256838",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notice the use of `tf.function`\n",
    "# This annotation causes the function to be \"compiled\".\n",
    "@tf.function\n",
    "def train_step(images):\n",
    "    \n",
    "    noise = tf.random.normal([BATCH_SIZE, noise_dim])\n",
    "    \n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        generated_images = generator(noise, training=True)\n",
    "        \n",
    "        real_output = discriminator(images, training=True)\n",
    "        fake_output = discriminator(generated_images, training=True)\n",
    "        \n",
    "        gen_loss = generator_loss(fake_output)\n",
    "        disc_loss = discriminator_loss(real_output, fake_output)\n",
    "\n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2fb30f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataset, epochs):\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        start = time.time()\n",
    "        \n",
    "        for image_batch in dataset:\n",
    "            train_step(image_batch)\n",
    "            \n",
    "        # To produce images for the GIF\n",
    "        display.clear_output(wait=True)\n",
    "        generate_and_save_images(generator, epoch + 1,seed)\n",
    "        \n",
    "        #To save the model every 15 epochs\n",
    "        if (epoch + 1) % 15 == 0:\n",
    "            checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "                \n",
    "        print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n",
    "        \n",
    "    display.clear_output(wait=True)\n",
    "    generate_and_save_images(generator, epochs, seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "905e9163",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_save_images(model, epoch, test_input):\n",
    "# Notice `training` is set to False.\n",
    "# This is so all layers run in inference mode (batchnorm).\n",
    "    predictions = model(test_input, training=False)\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    \n",
    "    for i in range(predictions.shape[0]):\n",
    "        plt.subplot(4, 4, i+1)\n",
    "        plt.imshow(predictions[i, :, :, 0] * 127.5 + 127.5)\n",
    "        plt.axis('off')\n",
    "        \n",
    "    plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6a523d9b",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/4_/b6dz99910pb5jx16ls85fszh0000gn/T/ipykernel_21177/490178149.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m                                 discriM=discriminator)\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/4_/b6dz99910pb5jx16ls85fszh0000gn/T/ipykernel_21177/4038277136.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(dataset, epochs)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mimage_batch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m             \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;31m# To produce images for the GIF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_counter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalled_without_tracing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    485\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    488\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1821\u001b[0m     \u001b[0;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1822\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1823\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1824\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1825\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1139\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1140\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1141\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1143\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1222\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[0;32m-> 1224\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1225\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    512\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(genG_optimizer=generator_optimizer,\n",
    "                                discriM_optimizer=discriminator_optimizer,\n",
    "                                genG=generator,\n",
    "                                discriM=discriminator)\n",
    "# Training\n",
    "train(train_dataset, EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb711131",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_image(epoch_no):\n",
    "    return PIL.Image.open('image_at_epoch_{:04d}.png'.format(epoch_no))\n",
    "display_image(EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5d2964",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Animated GIF of images\n",
    "anim_file = 'dcgan.gif'\n",
    "with imageio.get_writer(anim_file, mode='I') as writer:\n",
    "    filenames = glob.glob('image*.png')\n",
    "    filenames = sorted(filenames)\n",
    "    last = -1\n",
    "    for i,filename in enumerate(filenames):\n",
    "        frame = 2*(i**0.5)\n",
    "        if round(frame) > round(last):\n",
    "            last = frame\n",
    "        else:\n",
    "            continue\n",
    "        image = imageio.imread(filename)\n",
    "        writer.append_data(image)\n",
    "        image = imageio.imread(filename)\n",
    "        writer.append_data(image)\n",
    "    try:\n",
    "        from google.colab import files\n",
    "    except ImportError:\n",
    "        pass\n",
    "    else:\n",
    "        files.download(anim_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
